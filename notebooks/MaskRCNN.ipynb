{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaskRCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from tqdm import tqdm\n",
    "from yacs.config import CfgNode\n",
    "\n",
    "from src.config import default_map_builder_cfg, default_sim_cfg\n",
    "from src.features.mapping import SemanticMap3DBuilder\n",
    "from src.model.perception import map_processing\n",
    "from src.model.perception.labeler import LabelGenerator\n",
    "from src.utils import category_mapping\n",
    "from src.utils.category_mapping import get_instance_index_to_reseal_name_dict\n",
    "from src.utils.misc import get_semantic_map\n",
    "from src.visualisation import instance_map_visualization\n",
    "from src.visualisation.instance_map_visualization import visualize_2d_categorical_instance_map\n",
    "from src.visualisation.semantic_map_visualization import (\n",
    "    visualize_categorical_label_map,\n",
    "    visualize_semantic_map,\n",
    ")\n",
    "from src.model.perception.model_wrapper import ModelWrapper\n",
    "\n",
    "if pathlib.PurePath(os.getcwd()).name == 'notebooks':\n",
    "    print(pathlib.PurePath(os.getcwd()).name)\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAJECTORY = \"00006-HkseAnWCgqk\"\n",
    "ROOT = f\"./data/interim/trajectories/train/{TRAJECTORY}\"\n",
    "DEPTH_MAP_DIR = f\"./data/interim/trajectories/train/{TRAJECTORY}/D\"\n",
    "RGB_IMAGE_DIR = f\"./data/interim/trajectories/train/{TRAJECTORY}/RGB\"\n",
    "POSITIONS_FILE = f\"./data/interim/trajectories/train/{TRAJECTORY}/positions.npy\"\n",
    "ROTATIONS_FILE = f\"./data/interim/trajectories/train/{TRAJECTORY}/rotations.npy\"\n",
    "SEMANTIC_MAP_DIR = f\"./data/interim/trajectories/train/{TRAJECTORY}/Semantic\"\n",
    "trajectory_name = TRAJECTORY.split(\"-\")[1]\n",
    "SEMANTIC_INFO_FILE = f\"./data/raw/train/scene_datasets/hm3d/train/{TRAJECTORY}/{trajectory_name}.semantic.txt\"\n",
    "\n",
    "sim_cfg = default_sim_cfg()\n",
    "map_builder_cfg = default_map_builder_cfg()\n",
    "map_builder_cfg.NUM_SEMANTIC_CLASSES = 6\n",
    "map_builder_cfg.RESOLUTION = 0.05\n",
    "map_builder_cfg.MAP_SIZE = [25, 1.5, 25]\n",
    "map_builder_cfg.GET_ENTIRE_MAP = True\n",
    "map_builder = SemanticMap3DBuilder(map_builder_cfg, sim_cfg)\n",
    "\n",
    "model_config = CfgNode()\n",
    "model_config.USE_INITIAL_TRANSFORMS = True\n",
    "model_config.SCORE_THRESHOLD = 0.5\n",
    "model_config.MASK_THRESHOLD = 0.5\n",
    "model = ModelWrapper(model_config)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:53<00:00,  7.41it/s]\n"
     ]
    }
   ],
   "source": [
    "rotations = np.load(ROTATIONS_FILE).view(dtype=np.quaternion)\n",
    "positions = np.load(POSITIONS_FILE)\n",
    "scene_index_to_category_index_map = category_mapping.get_scene_index_to_reseal_index_vectorized(SEMANTIC_INFO_FILE)\n",
    "\n",
    "map_builder.clear()\n",
    "\n",
    "def load_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image / 255\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(0,400)):\n",
    "    depth_map = np.load(f\"{DEPTH_MAP_DIR}/{i}.npy\")\n",
    "    rgb_image = load_image(f\"{RGB_IMAGE_DIR}/{i}.png\")\n",
    "    map = model(rgb_image)\n",
    "    # saved_semantics = np.load(f\"{SEMANTIC_MAP_DIR}/{i}.npy\")\n",
    "    # map = get_semantic_map(saved_semantics, scene_index_to_category_index_map, map_builder_cfg.NUM_SEMANTIC_CLASSES)\n",
    "    pose = (positions[i], rotations[i])\n",
    "    map_builder.update_point_cloud(map, depth_map, pose)\n",
    "    if i % 10 == 1:\n",
    "        map_builder.update_semantic_map()\n",
    "\n",
    "map_builder.update_semantic_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_map = map_builder.semantic_map\n",
    "map_processor_cfg = CfgNode()\n",
    "map_processor_cfg.NO_OBJECT_CONFIDENCE_THRESHOLD = 0.5\n",
    "map_processor_cfg.HOLE_VOXEL_THRESHOLD = 2000\n",
    "map_processor_cfg.OBJECT_VOXEL_THRESHOLD = 200\n",
    "map_processor_cfg.DILATE = True\n",
    "\n",
    "grid_index_of_origin = map_builder.get_grid_index_of_origin()\n",
    "\n",
    "label_generator = LabelGenerator(semantic_map, grid_index_of_origin, map_builder_cfg, map_processor_cfg, sim_cfg.SENSOR_CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.MaskRCNNDataset import MaskRCNNDataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from src.config import default_maskrcnn_cfg\n",
    "import torchvision\n",
    "maskrcnn_cfg = default_maskrcnn_cfg()\n",
    "transforms = torchvision.models.detection.MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT.transforms()\n",
    "mask_dataset = MaskRCNNDataset(ROOT, transforms=transforms, label_generator=label_generator)\n",
    "train_dataloader = DataLoader(mask_dataset, maskrcnn_cfg.BATCH_SIZE, maskrcnn_cfg.SHUFFLE)\n",
    "\n",
    "params =  [p for p in model.maskrcnn.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=maskrcnn_cfg.LEARNING_RATE,\n",
    "\t\t\t\t\t\t\tmomentum=maskrcnn_cfg.OPTIM_MOMENTUM, \n",
    "\t\t\t\t\t\t\tweight_decay=maskrcnn_cfg.OPTIM_WEIGHT_DECAY)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\tstep_size=maskrcnn_cfg.OPTIM_STEP_SIZE,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tgamma=maskrcnn_cfg.OPTIM_GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [07:33<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images with labels: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [07:40<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images with labels: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [07:11<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images with labels: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 362/451 [05:39<01:36,  1.08s/it]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(maskrcnn_cfg.NUM_EPOCHS):\n",
    "\tprint(\"Epoch \"+str(epoch)+\":\")\n",
    "\tcount = 0\n",
    "\tfor image, target in tqdm(train_dataloader):\n",
    "\t\tif target['boxes'].shape[1] == 0:\n",
    "\t\t\tcontinue\n",
    "\t\ttarget['boxes'] = target['boxes'][0]\n",
    "\t\ttarget['labels'] = target['labels'][0]\n",
    "\t\ttarget['masks'] = target['masks'][0]\n",
    "\t\t\n",
    "\t\tloss = model(model_input=image, labels=target)['loss_mask']\n",
    "\t\t\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tlr_scheduler.step()\n",
    "\t\tcount += 1\n",
    "\tprint(\"number of images with labels: \"+str(count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_builder.clear()\n",
    "\n",
    "for i in tqdm(range(0,400)):\n",
    "    depth_map = np.load(f\"{DEPTH_MAP_DIR}/{i}.npy\")\n",
    "    rgb_image = load_image(f\"{RGB_IMAGE_DIR}/{i}.png\")\n",
    "    map = model(rgb_image)\n",
    "    # saved_semantics = np.load(f\"{SEMANTIC_MAP_DIR}/{i}.npy\")\n",
    "    # map = get_semantic_map(saved_semantics, scene_index_to_category_index_map, map_builder_cfg.NUM_SEMANTIC_CLASSES)\n",
    "    pose = (positions[i], rotations[i])\n",
    "    map_builder.update_point_cloud(map, depth_map, pose)\n",
    "    if i % 10 == 1:\n",
    "        map_builder.update_semantic_map()\n",
    "\n",
    "map_builder.update_semantic_map()\n",
    "\n",
    "label_generator = LabelGenerator(semantic_map, grid_index_of_origin, map_builder_cfg, map_processor_cfg, sim_cfg.SENSOR_CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = visualize_categorical_label_map(label_generator.categorical_label_map, opacity=0.1)\n",
    "\n",
    "# If nothing shows up, try changing jupyter_backend=\"trame\" to jupyter_backend=\"panel\"\n",
    "plotter.show(jupyter_backend=\"panel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = instance_map_visualization.visualize_3d_categorical_instance_map(\n",
    "    label_generator.categorical_instance_map, \n",
    "    label_generator.categorical_label_map, \n",
    "    0.1)\n",
    "# If nothing shows up, try changing jupyter_backend=\"trame\" to jupyter_backend=\"panel\"\n",
    "plotter.show(jupyter_backend=\"panel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 ('habitat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334581d5fae70a3394a0b95016f9fd1a46cc109bef43a220fa0ce1a6eb571224"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
