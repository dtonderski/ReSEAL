{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.mapping import SemanticMap3DBuilder\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "from yacs.config import CfgNode\n",
    "from src.model.perception.perception_pipeline_config import get_perception_cfg\n",
    "from src.model.perception.evaluation import get_ground_truth\n",
    "from src.model.perception.labeler import LabelGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from src.model.perception.model_wrapper import ModelWrapper\n",
    "from PIL import Image\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebooks\n"
     ]
    }
   ],
   "source": [
    "if pathlib.PurePath(os.getcwd()).name == \"notebooks\":\n",
    "    print(pathlib.PurePath(os.getcwd()).name)\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = '00800-TEEsavR23oF'\n",
    "epoch = 0\n",
    "TRAJECTORY_DIR = pathlib.Path('data') / 'interim' / 'trajectories' / '23-06-11,16:09:05' / f'epoch_{epoch}' / scene_id\n",
    "SEMANTIC_INFO_PATH = (pathlib.Path('data') / 'raw' / 'minival' / 'scene_datasets' / 'hm3d' / 'minival' \n",
    "                      / scene_id / f'{scene_id.split(\"-\")[1]}.semantic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantics_list = []\n",
    "rgb_list = []\n",
    "truth_dicts = []\n",
    "for i in [142, 143, 144]:\n",
    "    semantics = np.load(TRAJECTORY_DIR / 'Semantic' / f'{i}.npy')\n",
    "    semantics_list.append(semantics)\n",
    "    rgb_list.append(Image.open(TRAJECTORY_DIR / 'RGB' / f'{i}.png'))\n",
    "    truth_dicts.append(get_ground_truth(semantics, SEMANTIC_INFO_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.perception.perception_pipeline_config import get_perception_cfg\n",
    "from src.data.MaskRCNNEvaluationDataset import MaskRCNNEvaluationDataset, eval_collate_fn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "perception_cfg = get_perception_cfg()\n",
    "perception_cfg.DATA_PATHS.TRAJECTORIES_DIR = str(Path(\n",
    "        perception_cfg.DATA_PATHS.INTERIM_DATA_DIR, \"trajectories\", \"23-06-11,16:09:05\"))\n",
    "\n",
    "eval_dataset = MaskRCNNEvaluationDataset(perception_cfg.DATA_PATHS, perception_cfg.DATA_GENERATOR.SPLIT, 0)\n",
    "eval_dataloader = DataLoader(eval_dataset,\n",
    "                                batch_size=perception_cfg.TRAINING.BATCH_SIZE,\n",
    "                                shuffle=perception_cfg.TRAINING.SHUFFLE,\n",
    "                                num_workers=perception_cfg.TRAINING.NUM_WORKERS,\n",
    "                                collate_fn=eval_collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35634133219718933\n",
      "0.2227722704410553\n",
      "0.11303630471229553\n",
      "0.0\n",
      "0.08580858260393143\n",
      "0.2940044105052948\n",
      "0.30845391750335693\n",
      "0.0717821791768074\n",
      "0.11689918488264084\n",
      "0.1158415824174881\n",
      "0.38151815533638\n",
      "0.07897218316793442\n",
      "0.06435643881559372\n",
      "0.0\n",
      "0.08415841311216354\n",
      "0.3014301359653473\n",
      "0.5940043926239014\n",
      "0.0\n",
      "0.22442243993282318\n",
      "0.0\n",
      "0.2564827799797058\n",
      "0.17326731979846954\n",
      "0.0631188154220581\n",
      "0.30693069100379944\n",
      "0.012376237660646439\n",
      "0.15951594710350037\n",
      "0.1262376308441162\n",
      "0.09460946172475815\n",
      "0.1920173168182373\n",
      "-1.0\n",
      "0.2524752616882324\n",
      "0.11221121996641159\n",
      "0.43399345874786377\n",
      "0.1283828467130661\n",
      "0.021039603278040886\n",
      "0.09075907617807388\n",
      "0.08415841311216354\n",
      "0.18069307506084442\n",
      "0.08085808902978897\n",
      "-1.0\n",
      "0.422442227602005\n",
      "0.5049505233764648\n",
      "0.3333333432674408\n",
      "-1.0\n",
      "0.24917492270469666\n",
      "0.21342132985591888\n",
      "0.3696369528770447\n",
      "0.15429043769836426\n",
      "0.08580858260393143\n",
      "0.0864686518907547\n",
      "0.056105609983205795\n",
      "0.11221121996641159\n",
      "0.21913142502307892\n",
      "0.1683168262243271\n",
      "0.08580858260393143\n",
      "0.5544553995132446\n",
      "0.07735148817300797\n",
      "0.38967469334602356\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.16584157943725586\n",
      "0.0\n",
      "0.1666666716337204\n",
      "0.15181519091129303\n",
      "0.3124312460422516\n",
      "0.05775577574968338\n",
      "0.024752475321292877\n",
      "0.10034161061048508\n",
      "0.0\n",
      "0.5181518197059631\n",
      "0.16707921028137207\n",
      "0.0\n",
      "0.32893288135528564\n",
      "0.33006536960601807\n",
      "0.3762376308441162\n",
      "0.04207920655608177\n",
      "0.13531352579593658\n",
      "0.27830034494400024\n",
      "0.1683168262243271\n",
      "0.7524752616882324\n",
      "0.0\n",
      "0.12156215310096741\n",
      "0.25544553995132446\n",
      "0.25280526280403137\n",
      "0.4455445408821106\n",
      "0.0\n",
      "0.08415841311216354\n",
      "0.056105609983205795\n",
      "0.5016501545906067\n",
      "0.4027581214904785\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m images, semantics, semantic_info_paths \u001b[39min\u001b[39;00m eval_dataloader:\n\u001b[0;32m----> 2\u001b[0m     ground_truths \u001b[39m=\u001b[39m [get_ground_truth(semantics[i], semantic_info_paths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(images))]\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mget_metrics(images, ground_truths))\n",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m images, semantics, semantic_info_paths \u001b[39min\u001b[39;00m eval_dataloader:\n\u001b[0;32m----> 2\u001b[0m     ground_truths \u001b[39m=\u001b[39m [get_ground_truth(semantics[i], semantic_info_paths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(images))]\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mget_metrics(images, ground_truths))\n",
      "File \u001b[0;32m/workspaces/ReSEAL/src/model/perception/evaluation.py:22\u001b[0m, in \u001b[0;36mget_ground_truth\u001b[0;34m(semantics, semantic_info_file_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_ground_truth\u001b[39m(semantics: NDArray[Shape[\u001b[39m\"\u001b[39m\u001b[39m256, 256\u001b[39m\u001b[39m\"\u001b[39m], UInt8], semantic_info_file_path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GroundTruthDict:\n\u001b[1;32m     21\u001b[0m     mapping \u001b[39m=\u001b[39m get_scene_index_to_reseal_index_vectorized(semantic_info_file_path)\n\u001b[0;32m---> 22\u001b[0m     reseal_semantics \u001b[39m=\u001b[39m mapping(semantics)\n\u001b[1;32m     23\u001b[0m     semantics \u001b[39m=\u001b[39m semantics\u001b[39m*\u001b[39m(reseal_semantics\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m     boxes \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/habitat/lib/python3.9/site-packages/numpy/lib/function_base.py:2304\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2301\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[1;32m   2302\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[0;32m-> 2304\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n",
      "File \u001b[0;32m/opt/conda/envs/habitat/lib/python3.9/site-packages/numpy/lib/function_base.py:2387\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2384\u001b[0m \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m   2385\u001b[0m inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[0;32m-> 2387\u001b[0m outputs \u001b[39m=\u001b[39m ufunc(\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2389\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2390\u001b[0m     res \u001b[39m=\u001b[39m asanyarray(outputs, dtype\u001b[39m=\u001b[39motypes[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for images, semantics, semantic_info_paths in eval_dataloader:\n",
    "    ground_truths = [get_ground_truth(semantics[i], semantic_info_paths[i]) for i in range(len(images))]\n",
    "    print(model.get_metrics(images, ground_truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
